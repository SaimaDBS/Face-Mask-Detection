{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkDQhgWkFMkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55deae0-b40e-47e0-8114-a41603ac072f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-3.13.0-py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.13.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.43.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.23.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.10.0.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (12.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
            "Installing collected packages: tensorflowjs\n",
            "Successfully installed tensorflowjs-3.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commenting by Jawad Ahmed\n",
        "Bscs201959"
      ],
      "metadata": {
        "id": "Jx1e9r2UUPBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google drive"
      ],
      "metadata": {
        "id": "uWHhut0XK7Pm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txntet7M62Xy",
        "outputId": "609686f3-fe17-433c-efcf-a0d2d5c51c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the training dataset and give the path of file in the drive"
      ],
      "metadata": {
        "id": "4AZJ8QajLAzD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1x1YwLiM648v"
      },
      "outputs": [],
      "source": [
        "trainingDataset = []\n",
        "classNumber = 0\n",
        "img_size = 100\n",
        "path = \"/content/drive/MyDrive/dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required libraries"
      ],
      "metadata": {
        "id": "OL9NdfFtLHwG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzQs4d7v68JB"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflowjs as tfjs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the images from the drive. Also give it a class name like 0, 1 etc. And append it in the training dataset."
      ],
      "metadata": {
        "id": "NQR3bChCSCQj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4ql94Cf7BJC",
        "outputId": "b23eeb21-896e-4182-f589-e268cf456a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1372\n",
            "2\n",
            "[array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 0, ..., 0, 0, 0],\n",
            "       [1, 1, 0, ..., 0, 0, 0]]), 0]\n"
          ]
        }
      ],
      "source": [
        "trainingDataset.clear()\n",
        "for folder in (os.listdir(path)):\n",
        "  print(classNumber)\n",
        "  fp = os.path.join(path,folder)\n",
        "  for eachImage in os.listdir(fp):\n",
        "    imagePath = os.path.join(fp,eachImage)\n",
        "    img = (cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE))/255\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    img= img.astype(int)\n",
        "    trainingDataset.append([img,classNumber])\n",
        "  classNumber = classNumber + 1\n",
        "\n",
        "print(len(trainingDataset))\n",
        "print(len(trainingDataset[0]))\n",
        "print(trainingDataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all tensorflow"
      ],
      "metadata": {
        "id": "CMqYqJPESpUA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USsoya6m7BBk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pickle\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomized the training dataset because CNN work effectively in random cases. Also separate the feature and label"
      ],
      "metadata": {
        "id": "F_uU9iT6StSY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbJVKc2_7AhP",
        "outputId": "7e5ab97a-5c3d-40a2-b404-cf45e2e46080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "Y = []\n",
        "img_size = 100\n",
        "np.random.shuffle(trainingDataset)\n",
        "for features, label in trainingDataset:\n",
        "    X.append(features)\n",
        "    Y.append(label)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape the X train and make the classes categorical representation."
      ],
      "metadata": {
        "id": "SCRQqClaS-JL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ktc0O07Gys",
        "outputId": "ffbdfb63-1c15-46f5-bf7f-2a94ae9499ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
        "Y_binary = to_categorical(Y)\n",
        "print(Y_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the model according to the requirements. Use the model sequentially."
      ],
      "metadata": {
        "id": "7n73zmxeTGoo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaLfSKvJ6uuG"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(40, (2, 2), input_shape=(100,100,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(60, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(80, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        " \n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the model compiled"
      ],
      "metadata": {
        "id": "OJjz3xhDTSD4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkGkwx4V7Hem"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pass the X train and y train dataset to the model using fit function. Also keep the epochs 20 for better result and training"
      ],
      "metadata": {
        "id": "Z9Nw9oZtTXcv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-1MXwF87PvD",
        "outputId": "cc4b7502-b5f7-4faf-ede6-ff55278b180e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "22/22 [==============================] - 11s 79ms/step - loss: 0.7024 - accuracy: 0.4986 - val_loss: 0.6928 - val_accuracy: 0.4764\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.6889 - accuracy: 0.5451 - val_loss: 0.6932 - val_accuracy: 0.4582\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 1s 48ms/step - loss: 0.6819 - accuracy: 0.5515 - val_loss: 0.6971 - val_accuracy: 0.4836\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 1s 52ms/step - loss: 0.6673 - accuracy: 0.5725 - val_loss: 0.7153 - val_accuracy: 0.4800\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 1s 48ms/step - loss: 0.6591 - accuracy: 0.5934 - val_loss: 0.7093 - val_accuracy: 0.5055\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.6362 - accuracy: 0.5998 - val_loss: 0.7310 - val_accuracy: 0.5455\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 1s 51ms/step - loss: 0.6118 - accuracy: 0.6335 - val_loss: 0.7753 - val_accuracy: 0.4982\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 1s 52ms/step - loss: 0.5983 - accuracy: 0.6381 - val_loss: 0.8134 - val_accuracy: 0.5127\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.5692 - accuracy: 0.6682 - val_loss: 0.8753 - val_accuracy: 0.5200\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 1s 52ms/step - loss: 0.5405 - accuracy: 0.6682 - val_loss: 0.9910 - val_accuracy: 0.5055\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.5383 - accuracy: 0.6800 - val_loss: 0.9458 - val_accuracy: 0.4873\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.5033 - accuracy: 0.7028 - val_loss: 1.2200 - val_accuracy: 0.4836\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.4912 - accuracy: 0.7156 - val_loss: 1.0733 - val_accuracy: 0.4836\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.4746 - accuracy: 0.7138 - val_loss: 1.2167 - val_accuracy: 0.4909\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 1s 52ms/step - loss: 0.4585 - accuracy: 0.7284 - val_loss: 1.2912 - val_accuracy: 0.4836\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.4394 - accuracy: 0.7265 - val_loss: 1.3629 - val_accuracy: 0.4836\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 1s 50ms/step - loss: 0.4546 - accuracy: 0.7238 - val_loss: 1.4200 - val_accuracy: 0.4836\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.4224 - accuracy: 0.7429 - val_loss: 1.4601 - val_accuracy: 0.4873\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 1s 51ms/step - loss: 0.4240 - accuracy: 0.7366 - val_loss: 1.6143 - val_accuracy: 0.4655\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 1s 51ms/step - loss: 0.4075 - accuracy: 0.7466 - val_loss: 1.5148 - val_accuracy: 0.4909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff080296bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.fit(X, Y_binary,\n",
        "          batch_size = 50,\n",
        "          epochs=20, validation_split = 0.2)\n",
        " \n",
        "# model.save(\"/content/drive/MyDrive/{NAME}.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the given file that we want to predicts."
      ],
      "metadata": {
        "id": "fbro17mSTmAo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86Mq1nka7Sxs"
      },
      "outputs": [],
      "source": [
        "def prepare(filepath):\n",
        "    img_size = 100 \n",
        "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)/255  \n",
        "    img_resize = cv2.resize(img, (img_size, img_size))  \n",
        "    return img_resize.reshape(-1, img_size, img_size, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the result by passing an image without mask so it give 73 percent prediction which is quite good."
      ],
      "metadata": {
        "id": "w_dJOd9bTx3C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zYm-mQV7WQT",
        "outputId": "7a3ef881-887d-4381-e19d-90ce76da6fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.26425108 0.73574895]]\n",
            "Without Mask\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(prepare(\"/content/drive/MyDrive/Mask Test/0.jpg\"))\n",
        "print((prediction))\n",
        "\n",
        "CATEGORIES = [\"With Mask\", \"Without Mask\"]\n",
        "\n",
        "pred_class = CATEGORIES[np.argmax(prediction)]\n",
        "print(pred_class)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN Face Mask Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}